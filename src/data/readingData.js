// Auto-generated from Google Sheets on 2025-09-18T22:16:44.484948
// Do not edit this file manually - changes will be overwritten

export const allSampleData = [
  {
    "id": "how_to_lie_with_statistics",
    "title": "How To Lie With Statistics",
    "author": "Darrell Huff",
    "link": "https://www.amazon.de/How-Lie-Statistics-Darrell-Huff/dp/0393310728",
    "type": "book",
    "platform": "",
    "language": "English",
    "tags": [
      "data science",
      "statistics",
      "mathematics",
      "analytical thinking"
    ],
    "status": "read",
    "rating": 5,
    "ratingDescription": "",
    "keyInsights": "",
    "quotes": [],
    "impact": null,
    "length": "Medium",
    "difficulty": "Intermediate",
    "relatedTo": [],
    "personalReflection": "",
    "citationFormat": "",
    "dateAdded": "4/3/2025",
    "dateRead": "03/01/2025"
  },
  {
    "id": "the_art_of_statistics:_how_to_learn_from_data",
    "title": "The Art of Statistics: How to Learn from Data",
    "author": "David Spiegelhalter",
    "link": "https://www.penguin.co.uk/books/294857/the-art-of-statistics-by-spiegelhalter-david/9780241258767",
    "type": "book",
    "platform": "",
    "language": "English",
    "tags": [
      "data science",
      "statistics",
      "mathematics",
      "analytical thinking",
      "reading from data"
    ],
    "status": "in-progress",
    "rating": null,
    "ratingDescription": "",
    "keyInsights": "",
    "quotes": [],
    "impact": null,
    "length": "Medium",
    "difficulty": "Intermediate",
    "relatedTo": [],
    "personalReflection": "",
    "citationFormat": "",
    "dateAdded": "7/24/2025",
    "dateRead": ""
  },
  {
    "id": "mahabir_pun",
    "title": "Mahabir Pun",
    "author": "Mahahir Pun",
    "link": "https://bookslandnepal.com/product/mahabir-pun",
    "type": "book",
    "platform": "",
    "language": "English",
    "tags": [
      "biography",
      "life",
      "struggle",
      "inspiration"
    ],
    "status": "read",
    "rating": 4,
    "ratingDescription": "",
    "keyInsights": "",
    "quotes": [],
    "impact": null,
    "length": "Long",
    "difficulty": "",
    "relatedTo": [],
    "personalReflection": "",
    "citationFormat": "",
    "dateAdded": "11/13/2024",
    "dateRead": "11/01/2024"
  },
  {
    "id": "calling_bullshit:_the_art_of_skepticism_in_a_data_",
    "title": "Calling Bullshit: The Art of Skepticism in a Data-Driven World",
    "author": "Carl T. Bergstrom, Jevin D. West",
    "link": "https://www.amazon.com/Calling-Bullshit-Skepticism-Data-Driven-World/dp/0525509186",
    "type": "book",
    "platform": "",
    "language": "English",
    "tags": [
      "statistics",
      "analytics",
      "data science",
      "mathematics",
      "analytical thinking"
    ],
    "status": "to-read",
    "rating": null,
    "ratingDescription": "",
    "keyInsights": "",
    "quotes": [],
    "impact": null,
    "length": "",
    "difficulty": "Advanced",
    "relatedTo": [],
    "personalReflection": "",
    "citationFormat": "",
    "dateAdded": "8/14/2025",
    "dateRead": ""
  },
  {
    "id": "breaking_the_sorting_barrier_for_directed_single_s",
    "title": "Breaking the Sorting Barrier for Directed Single-Source Shortest\r\nPaths",
    "author": "Ran Duan ∗,\r\nJiayi Mao ∗, Xiao Mao †,  Xinkai Shu, ‡ Longhui Yin ∗",
    "link": "https://arxiv.org/pdf/2504.17033",
    "type": "article",
    "platform": "",
    "language": "English",
    "tags": [
      "algorithm",
      "analysis",
      "Dijkstra's algorithm",
      "shortest path",
      "record break"
    ],
    "status": "read",
    "rating": null,
    "ratingDescription": "",
    "keyInsights": "The first result to break the O(m + n log n) time bound of Dijkstra’s algorithm on sparse graphs showing that it is not optimal for SSSP. Gives a deterministic O(m log2/3 n)-time algorithm for single-source shortest paths (SSSP) on directed graphs with real non-negative edge weights in the comparison-addition model\n\n1. Finds key vertices to reduce the frontiers (set of vertices you have reached in the current layer)\n\n2. Uses Bellman-Ford-style relaxations (\"checking if the currently known distance to a vertex can be improved by going through another vertex and if so, update it\" - ChatGPT)\n\n3. Performs partial Bread First Search\n\nThis algorithm doesn't track all the vertices, it only keeps a subset of these vertices.",
    "quotes": [],
    "impact": null,
    "length": "",
    "difficulty": "Advanced",
    "relatedTo": [],
    "personalReflection": "",
    "citationFormat": "",
    "dateAdded": "8/15/2025",
    "dateRead": "08/15/2025"
  },
  {
    "id": "statistical_methods:_basic_concepts,_interpretatio",
    "title": "Statistical methods: Basic concepts, interpretations, and cautions",
    "author": "Sander Greenland, Professor Emeritus \r\nDepartment of Epidemiology and Department of Statistics \r\nUniversity of California, Los Angeles",
    "link": "https://arxiv.org/pdf/2508.10168",
    "type": "article",
    "platform": "",
    "language": "English",
    "tags": [
      "statistics",
      "inference",
      "interpretation",
      "hypothesis testing",
      "confidence"
    ],
    "status": "in-progress",
    "rating": null,
    "ratingDescription": "",
    "keyInsights": "",
    "quotes": [],
    "impact": null,
    "length": "Short",
    "difficulty": "",
    "relatedTo": [],
    "personalReflection": "",
    "citationFormat": "",
    "dateAdded": "08/18/2025",
    "dateRead": ""
  },
  {
    "id": "ai_and_memory_wall",
    "title": "AI and Memory Wall",
    "author": "Amir Gholami1,2 Zhewei Yao1 Sehoon Kim1 Coleman Hooper1 Michael W. Mahoney1,2,3 Kurt Keutzer1\r\n1University of California, Berkeley 2\r\nICSI 3LBNL",
    "link": "https://arxiv.org/pdf/2403.14123",
    "type": "article",
    "platform": "",
    "language": "English",
    "tags": [
      "ai",
      "memory bound",
      "bottleneck",
      "run-time",
      "decoder models",
      "deep learning"
    ],
    "status": "read",
    "rating": null,
    "ratingDescription": "",
    "keyInsights": "1. One needs to study the arithmetic intensity of the operations involved. Arithmetic intensity is the number of FLOPs that can be performed per byte loaded from memory. Computed by dividing the total number of FLOPs by the total number of bytes accessed (also referred to as MOPs, or memory operations).\n2. Memory wall can become a major bottleneck for decoder models (at low batch sizes) and not compute.",
    "quotes": [],
    "impact": null,
    "length": "Short",
    "difficulty": "",
    "relatedTo": [],
    "personalReflection": "Memory wall/bounds with large batch-size lead to sharp minimum, that is, spiky loss curves and may reduce generalization.",
    "citationFormat": "",
    "dateAdded": "08/19/2025",
    "dateRead": "08/19/2025"
  },
  {
    "id": "breaking_the_memory_wall:_a_study_of_i/o_patterns_",
    "title": "Breaking the Memory Wall: A Study of I/O Patterns and GPU\r\nMemory Utilization for Hybrid CPU-GPU Offloaded Optimizers",
    "author": "Avinash Maurya, \nJie Ye, M. Mustafa Rafique,\nFranck Cappello,\nBogdan Nicolae,",
    "link": "https://arxiv.org/pdf/2406.10728v1",
    "type": "article",
    "platform": "",
    "language": "English",
    "tags": [
      "optimization",
      "memory-bound",
      "deep learning",
      "ai",
      "llms"
    ],
    "status": "read",
    "rating": null,
    "ratingDescription": "",
    "keyInsights": "It has revealed several important bottlenecks of ex\u0002isting implementations: \n\n1. redundant and/or blocking device-to-host and host-to-device data transfers that slow down the last backward pass and the update step, \n\n2. slow upload of updated model parameters back to the GPUs in half precision, \n\n3. fluctuations of GPU memory utilization and PCIe links that lead to underutilization of GPUs especially during the update step, \n\n4. contention for PCIe links due to 3D parallelism, and contention for the I/O bandwidth of the host memory due to concurrent data transfers and CPU computations.",
    "quotes": [],
    "impact": null,
    "length": "Short",
    "difficulty": "Intermediate",
    "relatedTo": [],
    "personalReflection": "",
    "citationFormat": "",
    "dateAdded": "08/19/2025",
    "dateRead": "08/19/2025"
  },
  {
    "id": "scheduling_deep_learning_jobs_in_multi_tenant_gpu_",
    "title": "Scheduling Deep Learning Jobs in Multi-Tenant GPU Clusters via Wise Resource Sharing",
    "author": "Yizhou Luo∗\r\n, Qiang Wang†\r\n, Shaohuai Shi†\r\n, Jiaxin Lai∗\r\n, Shuhan Qi†\r\n, Jiajia Zhang†\r\n, Xuan Wang†\r\nHarbin Institute of Technology (Shenzhen)\r\nGuangdong Provincial Key Laboratory of Novel Security Intelligence Technologies",
    "link": "https://arxiv.org/pdf/2407.13088",
    "type": "article",
    "platform": "",
    "language": "English",
    "tags": [
      "deep learnig",
      "job scheduling",
      "memory contention",
      "resource utilization"
    ],
    "status": "read",
    "rating": 5,
    "ratingDescription": "",
    "keyInsights": "1. Introduces a novel DDL job scheduling model enabling multiple jobs to fully or partially share the same set of GPUs while ensuring model convergence through gradi\u0002ent accumulation. Unlike existing methods that increase batch size and GPU numbers to enhance performance, risking accuracy degradation, our model focuses on GPU resource sharing across jobs and mitigates GPU memory constraints through gradient accumulation, thereby poten\u0002tially reducing queuing time for waiting DDL jobs.\n\n2. SJF-BSBF (shortest job first with best shar\u0002ing benefit first) reduces average job com\u0002pletion time by 27-33%.  \n\n3. Given that GPU memory constraints may limit the per-GPU batch size, some schedulers tackle this limitation through memory offloading (which may introduce additional system overhead) or by adjusting batch sizes and other training hyper-parameters (which may compromise model accuracy).\n\n4. Adopts the ”gang-scheduling” discipline widely prevalent in practical large-scale GPU clusters.\n\n5. Different jobs exhibit varying sensitivities to network communication and GPU workloads.\n\n6. Once the free GPU number is not enough to execute the job, they manage to look for those already occupied by the running jobs to schedule the new one. This is the core logic of SJF-BSBF.",
    "quotes": [],
    "impact": null,
    "length": "Short",
    "difficulty": "Intermediate",
    "relatedTo": [],
    "personalReflection": "GPU contention can negatively impact model convergence and final accuracy. The authors have shown that this can be mitigated using a non-preemptive scheduling heuristic (SJF-BSBF) that dynamically adjusts sub-batch sizes and sharing timings while ensuring both efficient GPU sharing and maintenance of Deep Learning model accuracy via gradient accumulation.",
    "citationFormat": "",
    "dateAdded": "08/19/2025",
    "dateRead": "08/19/2025"
  },
  {
    "id": "prompt_injection:_a_visual,_non_technical_primer_f",
    "title": "Prompt injection: A visual, non technical primer for ChatGPT users",
    "author": "Georg Zoeller",
    "link": "https://www.linkedin.com/pulse/prompt-injection-visual-primer-georg-zoeller-tbhuc/",
    "type": "linkedin_post",
    "platform": "linkedIn",
    "language": "English",
    "tags": [
      "chat gpt",
      "prompt injection",
      "llms",
      "ai"
    ],
    "status": "read",
    "rating": 5,
    "ratingDescription": "",
    "keyInsights": "LLMs, like many transformer based systems only have one input which must carry both the instructions and data into the depth of the model, where the determination is made in ways we have very little influence on. \r\n\r\nThis is an architectural limitation that has not budged since 2017, all agents are vulnerable to it on some level and there's no major credible breakthroughs on the horizon to reliably fix it.",
    "quotes": [],
    "impact": 5,
    "length": "Short",
    "difficulty": "Intermediate",
    "relatedTo": [
      "llms"
    ],
    "personalReflection": "Prompt injection can easily tweak the reasoning models into false conclusions. This is very evident in all the Agents based systems too. The question arises also about the security models like Co-Pilot was found leaking internal documents and CRM data. That concludes with the fact that every AI app is prone to high security loop hole. Any context engineer can very easily delude the halucinating AI models.",
    "citationFormat": "Q: Wait, doesn't that mean if I use ChatGPT or Perplexity to do research on the internet ... any page can change my instructions (\"Find the best...\"),  \n\nA: Sure it does. We've had a persistent prompt injection in our demo page, ai-ceo.org for a while which looks like this: So yes, Perplexity is kind of crap, it will just parrot whatever the page tells it to and produce a bunch of unrelated citations to make it look legitimate.\n\n Q: So it's really unfixable \n\nA: With current architecture yes. It is mitigatable, to some extend and if compute gets cheap enough (maybe around 100x more), I can imagine companies spending some of that budget for more defense at depth (\"panel of judges model\").  Personally I wouldn't suggest starting any projects under the assumption this will be fixable anytime soon. It's been like this for the last 7 years or so...|I will update this document should any major breakthroughs or seriously viable mitigation strategies emerge.",
    "dateAdded": "08/20/2025",
    "dateRead": "08/20/2025"
  },
  {
    "id": "weaponizing_image_scaling_against_production_ai_sy",
    "title": "Weaponizing image scaling against production AI systems",
    "author": "Kikimora Morozova, Suha Sabi Hussain",
    "link": "https://blog.trailofbits.com/2025/08/21/weaponizing-image-scaling-against-production-ai-systems/",
    "type": "article",
    "platform": "",
    "language": "English",
    "tags": [
      "machine-learning",
      "prompt-injections",
      "vulnerabilities",
      "exploits"
    ],
    "status": "read",
    "rating": 5,
    "ratingDescription": "",
    "keyInsights": "1. How attackers can exploit image scaling on Gemini CLI, Vertex AI Studio, Gemini’s web and API interfaces, Google Assistant, Genspark, and other production AI systems\n\n2.Agentic coding tools continue to lack sufficiently secure defaults, design patterns, or systematic defenses that minimize the possibility of impactful prompt injection.\n\n3. These image scaling attacks exploit downscaling algorithms (or image resampling algorithms), which perform interpolation to turn multiple high resolution pixel values into a single low resolution pixel value.\n\n4. While some downscaling algorithms are more vulnerable than others, attempting to identify the least vulnerable algorithm and implementation is not a robust approach.\n\n5. Image scaling attacks may be even more impactful on mobile and edge devices where fixed image sizes are more frequently enforced and suboptimal downscaling algorithms are readily available within the default frameworks and tools.",
    "quotes": [],
    "impact": 5,
    "length": "short",
    "difficulty": "Intermediate",
    "relatedTo": [
      "llms"
    ],
    "personalReflection": "As prompt injection is becoming extremly vulnerable, trail of bits have put forth an exploration and explaination to how an image can hide a pyload underneath. They appear totally harmless and simple at full resolution but when downscaled using techniques like Nearest Neighbor, Bilinear Interpolation, Bicubic Interpolation,  they can reveal hidden prompts designed to manipulate AI systems. This type of attacks are particularly dangerous as they use multi-modal prompt injection (embedding malicious instructions in visual data), and since users don't see the downscaled images (specially in API environments, small screen devices like mobile phones), the attack can go almost unnoticed.",
    "citationFormat": "",
    "dateAdded": "08/22/2025",
    "dateRead": "08/22/2025"
  },
  {
    "id": "adversarial_preprocessing:_understanding_and_preve",
    "title": "Adversarial Preprocessing: Understanding and Preventing\r\nImage-Scaling Attacks in Machine Learning",
    "author": "Erwin Quiring, David Klein, Daniel Arp, Martin Johns and Konrad Rieck",
    "link": "https://www.usenix.org/system/files/sec20fall_quiring_prepub.pdf",
    "type": "article",
    "platform": "",
    "language": "English",
    "tags": [
      "image scaling",
      "deep learning",
      "attacks"
    ],
    "status": "read",
    "rating": 5,
    "ratingDescription": "",
    "keyInsights": "1. Theoretically analyze the attacks from the perspective of signal processing and identify their root cause as the interplay of downsampling and convolution.\n\n2. Image scaling attack enables an ad\u0002versary to manipulate images, such that they change their appearance when scaled to a specific dimension. As a result,\nany learning-based system scaling images can be tricked into working on attacker-controlled data. \n\n3. The attacks can be used for poisoning data during training as well as misleading classifiers during prediction\n\n4. The un\u0002derlying mechanisms, however, are not understood so far and the root cause for adversarial scaling is still unknown.\n\n5. In particular, the attack generates an image A by slightly perturbing the source image S, such that its scaled version matches a target image T\n\n6.  The adversary needs to know two parameters:  (a) the used scaling algorithm and (b) the target size m×n of the scaling operation\n\n7.  Any signal can be described by a sum of sinusoids of different frequencies, and hence images can also be represented in the frequency domain\n\n8. Scaling algorithms do not merely reduce the frequencies in an image. These algorithms carefully interpo\u0002late the pixels of the source image before downscaling it in\norder to mitigate the aliasing effect.\n\n9. Only those pixels close to the center of the kernel receive a high weighting, whereas all remaining pixels play a limited role during scaling. If the step size exceeds the kernel width, some pixels are even ignored\nand irrelevant for the scaling operation.\n\n10. The adversary only needs to modify those pixels with high weights to control  the scaling and can leave the rest of the image untouched.\n\n11. Two objectives: Ensure Target and Attacking images are similar after downscaling (fooling the model), Source image and Attacking image are undetectable.\n\n12. Adaptive Attack: Uses standard image-scaling without knowledge of the defense, Non-Adaptive attack: Attacker knows the defense and adapts the attack strategy\n\n13. Both Pillow's dynamic scaling is robust to both adaptive and non-adaptive attacks and Area Scaling are robust against adaptive attacks \n\n14. Image re-construction is a strong defense against non-adaptive attacks\n\n15. Reconstruction defenses introduces noise and distortion making it harder to hide payloads",
    "quotes": [],
    "impact": null,
    "length": "long",
    "difficulty": "intermediate",
    "relatedTo": [],
    "personalReflection": "1. Image Scaling attack enables an adversary to manipulate images but changes their appearance when scaled to a specific dimension.\n2. Such attacks can even poison the training data and mislead the classifiers during prediction\n3. The technique can easily deduce the scaling algorithm that was used and also the dimension of the target image without prior knowledge. This is due to the fact that the most common libraries have limited number of scaling options.\n4. Area scaling and Image re-construction are proven to be more robust to defend the image scaling attacks.",
    "citationFormat": "",
    "dateAdded": "08/22/2025",
    "dateRead": "08/22/2025"
  }
];

export const getReadingStats = (data) => {
  const readItems = data.filter(item => item.status === 'read').length;
  const inProgress = data.filter(item => item.status === 'in-progress').length;
  const toRead = data.filter(item => item.status === 'to-read').length;
  
  const ratedItems = data.filter(item => item.rating !== null);
  const averageRating = ratedItems.length > 0 
    ? (ratedItems.reduce((sum, item) => sum + item.rating, 0) / ratedItems.length).toFixed(1)
    : 0;
    
  const impactItems = data.filter(item => item.impact !== null);
  const averageImpact = impactItems.length > 0
    ? (impactItems.reduce((sum, item) => sum + item.impact, 0) / impactItems.length).toFixed(1)
    : 0;

  return {
    totalItems: data.length,
    readItems,
    inProgress,
    toRead,
    averageRating: parseFloat(averageRating),
    averageImpact: parseFloat(averageImpact)
  };
};

export const getTagFrequency = (data) => {
  const tagCounts = {};
  data.forEach(item => {
    item.tags.forEach(tag => {
      tagCounts[tag] = (tagCounts[tag] || 0) + 1;
    });
  });
  return tagCounts;
};
